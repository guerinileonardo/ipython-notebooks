{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "============\n",
    "This notebook is the computational appendix of [arXiv:1609.06139](http://arxiv.org/abs/1609.06139). We demonstrate how to use some convenience functions to decide whether a qubit or qutrit POVM is simulable and how much noise is needed to make it simulable. We also give the details how to reproduce the numerical results shown in the paper. Furthermore, we show how to decompose a simulable POVM into a convex combination of projective measurements.\n",
    "\n",
    "To improve readability of this notebook, we placed the supporting functions to a [separate file](https://github.com/peterwittek/ipython-notebooks/blob/master/povm_tools.py); please download this in the same folder as the notebook if you would like to evaluate it. The following dependencies must also be available: the Python Interface for Conic Optimization Software [Picos](http://picos.zib.de/) and its dependency [cvxopt](http://cvxopt.org/), at least one SDP solver ([SDPA](http://sdpa.sourceforge.net/) as an executable in the path or [Mosek](http://mosek.com/) with its Python interface installed; cvxopt as a solver is not recommended), and a vertex enumerator ([cdd](https://www.inf.ethz.ch/personal/fukudak/cdd_home/) with its [Python interface](https://pypi.python.org/pypi/pycddlib) or [lrs/plrs](http://cgm.cs.mcgill.ca/~avis/C/lrs.html) as an executable in the path).\n",
    "\n",
    "First, we import everything we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import random\n",
    "import time\n",
    "from povm_tools import basis, check_ranks, complex_cross_product, dag, decomposePovmToProjective, \\\n",
    "    enumerate_vertices, find_best_shrinking_factor, get_random_qutrit, \\\n",
    "    get_visibility, Pauli, truncatedicosahedron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking criticial visibility\n",
    "=============================\n",
    "The question whether a qubit or qutrit POVM is simulable by projective measurements boils down to an SDP feasibility problem. Few SDP solvers can handle feasibility problems, so from a computational point of view, it is always easier to phrase the question as an SDP optimization, which would return the critical visibility, below which the amount of depolarizing noise would allow simulability. Recall Eq. (8) from the paper that defines the noisy POVM that we obtain subjecting a POVM $\\mathbf{M}$ to a depolarizing channel $\\Phi_t$:\n",
    "\n",
    "$\\left[\\Phi_t\\left(\\mathbf{M}\\right)\\right]_i := t M_i + (1-t)\\frac{\\mathrm{tr}(M_i)}{d} \\mathbb{1}$.\n",
    "\n",
    "If this visibility $t\\in[0,1]$ is one, the POVM $\\mathbf{M}$ is simulable.\n",
    "\n",
    "Qubit example\n",
    "-------------\n",
    "As an example, we study the tetrahedron measurement (see Appendix B in [arXiv:quant-ph/0702021](https://arxiv.org/abs/quant-ph/0702021)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dp(v):\n",
    "    result = np.eye(2, dtype=np.complex128)\n",
    "    for i in range(3):\n",
    "        result += v[i]*Pauli[i]\n",
    "    return result\n",
    "\n",
    "b = [np.array([ 1,  1,  1])/np.sqrt(3),\n",
    "     np.array([-1, -1,  1])/np.sqrt(3),\n",
    "     np.array([-1,  1, -1])/np.sqrt(3),\n",
    "     np.array([ 1, -1, -1])/np.sqrt(3)]\n",
    "M = [dp(bj)/4 for bj in b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we check with an SDP whether it is simulable by projective measurements. A four outcome qubit POVM $\\mathbf{M} \\in\\mathcal{P}(2,4)$ is simulable if and only if \n",
    "\n",
    "$M_{1}=N_{12}^{+}+N_{13}^{+}+N_{14}^{+},$\n",
    "\n",
    "$M_{2}=N_{12}^{-}+N_{23}^{+}+N_{24}^{+},$\n",
    "\n",
    "$M_{3}=N_{13}^{-}+N_{23}^{-}+N_{34}^{+},$\n",
    "\n",
    "$M_{4}=N_{14}^{-}+N_{24}^{-}+N_{34}^{-},$\n",
    "\n",
    "where Hermitian operators $N_{ij}^{\\pm}$ satisfy $N_{ij}^{\\pm}\\geq0$ and $N_{ij}^{+}+N_{ij}^{-}=p_{ij}\\mathbb{1}$, where $i<j$ , $i,j=1,2,3,4$ and $p_{ij}\\geq0$ as well as $\\sum_{i<j}p_{ij}=1$, that is, the $p_{ij}$ values form a probability vector. This forms an SDP feasibility problem, which we can rephrase as an optimization problem by adding depolarizing noise to the left-hand side of the above equations and maximizing the visibility $t$:\n",
    "\n",
    "$\\max_{t\\in[0,1]} t$\n",
    "\n",
    "such that\n",
    "\n",
    "$t\\,M_{1}+(1-t)\\,\\mathrm{tr}(M_{1})\\frac{\\mathbb{1}}{2}=N_{12}^{+}+N_{13}^{+}+N_{14}^{+},$\n",
    "\n",
    "$t\\,M_{2}+(1-t)\\,\\mathrm{tr}(M_{2})\\frac{\\mathbb{1}}{2}=N_{12}^{-}+N_{23}^{+}+N_{24}^{+},$\n",
    "\n",
    "$t\\,M_{3}+(1-t)\\,\\mathrm{tr}(M_{3})\\frac{\\mathbb{1}}{2}=N_{13}^{-}+N_{23}^{-}+N_{34}^{+},$\n",
    "\n",
    "$t\\,M_{4}+(1-t)\\,\\mathrm{tr}(M_{4})\\frac{\\mathbb{1}}{2}=N_{14}^{-}+N_{24}^{-}+N_{34}^{-}$.\n",
    "\n",
    "If it is, the critical visibility is one, we have a simulable measurement. We solve this SDP with the function `get_visibility` for the tetrahedron measurement, indicating that it is not simulable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8164966401734447"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_visibility(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qutrit example\n",
    "--------------\n",
    "We take the qutrit POVM from Section 4.1 in [arXiv:quant-ph/0310013](http://arxiv.org/abs/quant-ph/0310013):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "psi0 = np.array([[1/np.sqrt(2)], [1/np.sqrt(2)], [0]])\n",
    "omega = np.exp(2*np.pi*1j/3)\n",
    "D = [[omega**(j*k/2) * sum(np.power(omega, j*m) * np.kron(basis((k+m) % 3), basis(m).T)\n",
    "                           for m in range(3)) for k in range(1, 4)] for j in range(1, 4)]\n",
    "psi = [[D[j][k].dot(psi0) for k in range(3)] for j in range(3)]\n",
    "M = [np.kron(psi[k][j], psi[k][j].conj().T)/3 for k in range(3) for j in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SDP to be solved is more intricate than the qubit case. Using the notations of Lemma 14, let $\\mathbf{M}\\in\\mathcal{P}(d,n)$ be $n$-outcome measurement on $d$ dimensional Hilbert space. Let $m\\leq n$. The critical visibility $t_{m}(\\mathbf{M})$ can be computed via the following SPD programme\n",
    "\t\n",
    "$\\max_{t\\in[0,1]} t$\n",
    "\n",
    "Such that\n",
    "\n",
    "$t\\mathbf{M}+(1-t)\\left(\\mathrm{tr}(M_1)\\frac{\\mathbb{1}}{d},\\ldots,\\mathrm{tr}(M_n)\\frac{\\mathbb{1}}{d}\\right)=\\mathbf{M}=\\sum_{X\\in[n]_2} \\mathbf{N}_X + \\sum_{Y\\in[n]_3} \\mathbf{N}_Y$,\n",
    " \n",
    "$\\left\\{\\mathbf{N}_X\\right\\}_{X\\in[n]_3}\\ ,\\ \\left\\{p_X\\right\\}_{X\\in[n]_2}\\ , \\left\\{\\mathbf{N}_Y\\right\\}_{Y\\in[n]_3}\\ ,\\ \\left\\{p_Y\\right\\}_{X\\in[n]_3}$,\n",
    " \n",
    "$\\mathbf{M}=\\sum_{X\\in[n]_2} \\mathbf{N}_X + \\sum_{Y\\in[n]_3} \\mathbf{N}_Y$, \n",
    "\n",
    "$[\\mathbf{N}_X]_i \\geq 0\\ ,\\ [\\mathbf{N}_Y]_i \\geq 0\\,\\ \\ i=1,\\ldots,n$,   \n",
    "\n",
    "$[\\mathbf{N}_X]_i = 0$ for $i\\notin{X}, [\\mathbf{N}_Y]_i = 0$ for $i\\notin{Y}$,\n",
    "\n",
    "$\\mathrm{tr}\\left([\\mathbf{N}_Y]_i\\right) = p_Y$ for $i\\in{Y}$,\n",
    "\n",
    "$\\sum_{i=1}^n [\\mathbf{N}_X]_i= p_X \\mathbb{1}\\ , \\sum_{i=1}^n[\\mathbf{N}_Y]_i= p_Y \\mathbb{1}$\n",
    "\n",
    "$p_X \\geq 0\\ ,\\  p_Y\\geq 0\\ ,\\ \\sum_{X\\in[n]_2} p_X+\\sum_{Y\\in[n]_3} p_Y=1$.\n",
    "\n",
    "Solving this SDP for the qutrit POVM above, we see that the visibility is far from one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8057639895134708"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_visibility(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at a simulable POVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "psi = [get_random_qutrit()]\n",
    "psi.append(complex_cross_product(psi[0], np.array([[0], [0], [1]])))\n",
    "psi.append(complex_cross_product(psi[0], psi[1]))\n",
    "phi = [get_random_qutrit()]\n",
    "phi.append(complex_cross_product(phi[0], np.array([[0], [0], [1]])))\n",
    "phi.append(complex_cross_product(phi[0], phi[1]))\n",
    "M = [0.5*np.kron(psi[0], psi[0].conj().T),\n",
    "     0.5*np.kron(psi[1], psi[1].conj().T),\n",
    "     0.5*np.kron(psi[2], psi[2].conj().T) + 0.5*np.kron(phi[0], phi[0].conj().T),\n",
    "     0.5*np.kron(phi[1], phi[1].conj().T),\n",
    "     0.5*np.kron(phi[2], phi[2].conj().T),\n",
    "     np.zeros((3, 3), dtype=np.float64),\n",
    "     np.zeros((3, 3), dtype=np.float64),\n",
    "     np.zeros((3, 3), dtype=np.float64),\n",
    "     np.zeros((3, 3), dtype=np.float64)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is very close to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999990236691"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_visibility(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External polytopes approximating $\\mathcal{P}(2,4)$\n",
    "===================================================\n",
    "Here we repeat some of the theory we presented in Appendix D. We would like to find an external polytope that tightly approximates $\\mathcal{P}(2,4)$ and then check how much we have to \"shrink\" it until it fits inside the set of simulable POVMs. Since the operators $\\{\\mathbb{1}, \\sigma_x, \\sigma_y, \\sigma_z\\}$ form is a basis for the real space of Hermitian matrices $\\mathrm{Herm}(\\mathbb{C}^2)$, we can write any matrix in this set as $M = \\alpha \\mathbb{1} + x \\sigma_x + y \\sigma_y + z \\sigma_z$ for some $\\alpha, x, y, z$ real numbers. We relax the positivity condition of the measurement effects by requiring $\\mathrm{tr}(M|\\psi_j\\rangle\\langle\\psi_j|)\\geq0$ for some collection of pure states $\\{|\\psi_j\\rangle\\langle\\psi_j|\\}_{j=1}^N$, which in turn can always be expressed as $|\\psi_j\\rangle\\langle\\psi_j|=(1/2)(\\mathbb{1}-\\vec{v}_j \\cdot \\vec{\\sigma})$ for a vector $\\vec{v}_j$ from a unit sphere in $\\mathbb{R}^3$. Thus, with the measurement effects also expressed in the same basis, we can write the relaxed positivity conditions as\n",
    "\n",
    "$(x,y,z)\\cdot v_j \\leq \\alpha,\\  i=1,\\ldots,N$,\n",
    "\n",
    "where \"$\\cdot$\" denotes the standard inner product in $\\mathbb{R}^3$. We describe the approximating polytope as \n",
    "\n",
    "$\\begin{eqnarray}\n",
    "&\\alpha_i \\geq 0, \\ i=1,...,4, \\sum_i{\\alpha_i} = 1\\\\\n",
    "&\\sum_i{x_i} = \\sum_i{y_i} = \\sum_i{z_i} = 0.\n",
    "\\end{eqnarray}$\n",
    "\n",
    "This yields sixteen real parameters, which would be expensive to treat computationally. We can, however, exploit certain properties that reduce the number of parameters. First of all, since the effects add up to the identity, we can drop the last four parameters. Then, due to invariance properties and the characteristics of extremal POVMs, one parameter is sufficient for the first effect, and three are enough for the second. In total, we are left with eight parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to define inequalities defining the facets of the polytope, run a vertex enumeration algorithm, and refine the polytope further. From a computational perspective, a critical point is enumerating the vertices given the inequalities. For this, two major implementations are available that use fundamentally different algorithms:\n",
    "\n",
    " 1. [cdd](https://www.inf.ethz.ch/personal/fukudak/cdd_home/) and its [Python interface](http://pypi.python.org/pypi/pycddlib). \n",
    " 2. [lrs](http://cgm.cs.mcgill.ca/~avis/C/lrs.html) and its parallel variant [plrs](http://arxiv.org/abs/1510.02545). We developed a simple Python wrapper for this implementation.\n",
    "\n",
    "Using cdd results in fewer vertices, but lrs and plrs run at least a magnitude faster. The function `enumerate_vertices` abstracts away the implementation, and the user can choose between cdd, lrs, and plrs. Note that format of inequalities is $b+Ax\\geq 0$, where $b$ is the constant vector and $A$ is the coefficient matrix. Thus a line in our parametrization is of the form $[b_j, \\alpha_1, \\alpha_2, x_2, y_2, \\alpha_3, x_3, y_3, z_3]$, corresponding to an inequality $b_j +\\alpha_1 + \\alpha_2 + x_2 + y_2 + \\alpha_3 + x_3 + y_3 + z_3 \\geq 0$.\n",
    "\n",
    "Since $M_2$ lies in the plane, we consider a polygon approximating the circle from outside, rather than approximating the sphere. Furthermore, we can always assume that this vector lies in the $y$-positive semi-plane, and take a polygon approximating the semi-circle from the outside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 25\n",
    "W1 = np.zeros((n+3, 9))\n",
    "for i in range(n+1):\n",
    "    W1[i, 2:5] = [1, -np.cos(i*np.pi/n), -np.sin(i*np.pi/n)]\n",
    "# This constraint is to get only the half polygon with positive y2\n",
    "W1[n+1, 4] = 1\n",
    "# This constraint is to make the final polytope tangent to a rotated sic tetra\n",
    "W1[n+2, 2:5] = [1, 1./3, -np.sqrt(8)/3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to constrain the third effect $M_3$, and we start this approximation by defining a polytope approximating the unit sphere in $\\mathbb{R}^3$, which has the following vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = np.zeros((62, 3))\n",
    "v[:60] = truncatedicosahedron(1)\n",
    "\n",
    "v[60] = [-1/3, -np.sqrt(8)/6, np.sqrt(2/3)]\n",
    "v[61] = [-1/3, -np.sqrt(8)/6, -np.sqrt(2/3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last constraint is to be tangent to the tetrahedron. \n",
    "\n",
    "In the following step, we do two rounds of refinement to get the facets of a tighter approximation. We only do two rounds to keep computations feasible on a regular workstation. Further rounds require excessive computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    ext = enumerate_vertices(np.column_stack((np.ones((v.shape[0], 1)), -v)),\n",
    "                             method=\"plrs\")\n",
    "    w = np.zeros((ext.shape[0], 3))\n",
    "    for k in range(ext.shape[0]):\n",
    "        w[k] = ext[k][1:]/np.linalg.norm(ext[k][1:])\n",
    "    v = np.row_stack((v, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following constraints ensure that the third operator $M_3$ of the measurement is a quasi-effect, with the approximation given by $v$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2 = np.zeros((v.shape[0], 9))\n",
    "for i in range(v.shape[0]):\n",
    "    W2[i, 5:] = [1, -v[i, 0], -v[i, 1], -v[i, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of constraints ensures the same condition for the last effect, which we express by $\\mathbb{1} - M_1 - M_2 - M_3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W3 = np.zeros((v.shape[0], 9))\n",
    "for i in range(v.shape[0]):\n",
    "    W3[i] = [1, -1+v[i, 0], -1, v[i, 0], v[i, 1], -1,\n",
    "             v[i, 0], v[i, 1], v[i, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need that $\\alpha_0, \\alpha_1, \\alpha_2 \\geq 0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W4 = np.array([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also require that $\\alpha_0+\\alpha_1+\\alpha_2 \\leq 1$, which corresponds to expressing the previous constraint for the last effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W5 = np.array([[1, -1, -1, 0, 0, -1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need that $\\alpha_0 \\geq \\alpha_1 \\geq \\alpha_2 \\geq 1-\\alpha_0-\\alpha_1-\\alpha_2$, a condition that we can impose without lost of generality due to relabeling. Once we have the last constraints, we stack the vectors in a single array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W6 = np.array([[0, 1, -1, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 1, 0, 0, -1, 0, 0, 0],\n",
    "               [-1, 1, 1, 0, 0, 2, 0, 0, 0]])\n",
    "hull = np.row_stack((W1, W2, W3, W4, W5, W6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enumerate the vertices, which is a time-consuming operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex enumeration in 1219 seconds\n"
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "ext = enumerate_vertices(hull, method=\"plrs\", verbose=1)\n",
    "print(\"Vertex enumeration in %d seconds\" % (time.time()-time0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, we iterate the SDP optimization described in Section \"Checking criticial visibility\" over all vertices to get the best shrinking factor. This takes several hours to complete. Parallel computations do not work from a notebook, but they do when the script is executed in a console. For this reason, here we disable parallel computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KCurrent alpha: 0.815743 (done: 7.24%)       "
     ]
    }
   ],
   "source": [
    "time0 = time.time()\n",
    "alphas = find_best_shrinking_factor(ext, solver=\"mosek\", parallel=False)\n",
    "print(\"\\n Found in %d seconds\" % (time.time()-time0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decomposing simulable qutrit POVMs\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented the constructive strategy to find a projective decomposition for trace-one qutrit measurements $\\mathbf{M}\\in\\mathcal{P}_1(3,3)$ we described in Appendix D.\n",
    "\n",
    "First we define a function to generate a random trace-1 POVM. This is the only step that requires an additional dependency compared to the ones we loaded in the beginning of the notebook. The dependency is [QuTiP](http://qutip.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from qutip import rand_unitary\n",
    "\n",
    "def get_random_trace_one_povm(dim=3):\n",
    "    U = rand_unitary(dim)\n",
    "    M = [U[:, i]*dag(U[:, i]) for i in range(dim)]\n",
    "    for _ in range(dim-1):\n",
    "        U = rand_unitary(dim)\n",
    "        r = random.random()\n",
    "        for i in range(dim):\n",
    "            M[i] = r*M[i] + (1-r)*U[:, i]*dag(U[:, i])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we decompose a random POVM following the cascade of \"rank reductions\" described in Appendix D, and check the ranks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of POVM:  [3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "M = get_random_trace_one_povm()\n",
    "print(\"Rank of POVM: \", check_ranks(M))\n",
    "coefficients, projective_measurements = decomposePovmToProjective(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we look at the ranks of the effects of the individual projective measurements. We must point out that the numerical calculations occasionally fail, and we set the tolerance in rank calculations high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranks of projective measurements: \n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ranks of projective measurements: \")\n",
    "for measurement in projective_measurements:\n",
    "    print(check_ranks(measurement, tolerance=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show that the projective measurements indeed return the POVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = coefficients[0]*projective_measurements[0] + \\\n",
    "    coefficients[1]*(coefficients[2]*projective_measurements[1] + \n",
    "    coefficients[3]*(coefficients[4]*(coefficients[6]*projective_measurements[2] + \n",
    "    coefficients[7]*projective_measurements[3]) + \n",
    "    coefficients[5]*(coefficients[8]*projective_measurements[4] +\n",
    "                     coefficients[9]*projective_measurements[5])))\n",
    "not np.any(M - N > 10e-10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
