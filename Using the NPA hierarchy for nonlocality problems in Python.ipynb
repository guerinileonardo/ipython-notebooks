{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Introduction\n",
      "=========\n",
      "The original task was to generate the SDP relaxations of arbitrarily complex polynomial optimization problems of noncommuting variables, that is, the most general form of the NPA hierarchy [1] -- the tool for this conversion is called [Ncpol2sdpa](http://peterwittek.github.io/ncpol2sdpa/) [2]. Development started in MATLAB, with an eye on the libraries that achieve the same purpose for the Lasserre hierarchy, [Gloptipoly](http://homepages.laas.fr/henrion/software/gloptipoly/) and [SparsePOP](http://sparsepop.sourceforge.net/). Hence the approach was more algebraic from the beginning, rather than directly manipulating SDPs with [CVX](http://cvxr.com/cvx/), [SeDuMi](http://sedumi.ie.lehigh.edu/), or [Yalmip](http://users.isy.liu.se/johanl/yalmip/). Thus first it can be counterintuitive to use the library for quantum correlations. To further complicate things, MATLAB's noncommutative symbolic algebra capabilities were insufficient, hence development switched to using Python. The purpose of this notebook is to give a taste how it works.\n",
      "\n",
      "2. Preliminiaries\n",
      "=========\n",
      "We found that the most difficult part is getting Python running with the necessary libraries. By far the easiest solution is to download [Anaconda](https://store.continuum.io/cshop/anaconda/), which bundles all necessary libraries and tools needed on Windows, Linux, and OS X. This is especially preferred if you are using a restricted computer where you do not have admin rights. You can then install the current stable version of Ncpol2sdpa by typing ``pip install ncpol2sdpa`` on the command line. Other relevant libraries could prove more difficult to install, but we won't detail that here. If all works fine, you should be able to import all functions from the module:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from ncpol2sdpa import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other than a working Python installation with the necessary modules, you will also need an SDP solver. [SDPA](http://sdpa.sourceforge.net/) is the most recommended solver, which can be infinitely painful to set up. The rest of the tutorial assumes that the SDPA executable is in the path. See the section on alternative solvers if you cannot get SDPA working. CVXOPT, for instance, is included in Anaconda, and should work out of the box."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3. Working with projectors\n",
      "================\n",
      "3.1 Tsirelson bound for CHSH at level 4\n",
      "----------------------------------------------------\n",
      "We take a simple CHSH scenario in the probability picture first. As a simple example, we want to find the Tsirelson bound of the inequality. Say, we want a result at level 4, then we need to specify the measurement configuration of Alice and Bob, and the inequality in the Collins-Gisin notation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "level = 4\n",
      "Alice = [2, 2]\n",
      "Bob = [2, 2]\n",
      "I = [[ 0,   -1,    0 ],\n",
      "     [-1,    1,    1 ],\n",
      "     [ 0,    1,   -1 ]]\n",
      "print(maximum_violation(Alice, Bob, I, level))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-0.20710648902908663, -0.20710683598916801)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The value is negative because any kind of SDP generated **must** be a minimization, hence we flipped the sign of the objective function. The function ``maximum_violation`` hides the gory details. If we want to do something less trivial, we need to understand more of how it works. So let us do the same thing as above, but rolling out the steps. First of all, we need the symbolic operators representing the measurements of Alice and Bob:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "A = generate_measurements(Alice, 'A')\n",
      "B = generate_measurements(Bob, 'B')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For instance, now Alice has two sets of Hermitian operators:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[[A00], [A10]]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first index encodes the measurement, the second the operator within the measurement. Clearly, $A_{01}$ and $A_{11}$ are missing, because we are in the Collins-Gisin notation.\n",
      "\n",
      "These operators are Hermitian, but there is nothing telling that they are projectors. There algebra is defined through substitution rules that ensures a unique monomial for arbitrary multiplications of the operators of Alice and Bob."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "substitutions = projective_measurement_constraints(A, B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above function can extend to arbitrary number of parties, measurements and measurement outputs. Let's take a look at the obtained substitutions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "substitutions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "{A00**2: A00,\n",
        " B00*A10: A10*B00,\n",
        " B10*A00: A00*B10,\n",
        " B10**2: B10,\n",
        " B00**2: B00,\n",
        " A10**2: A10,\n",
        " B00*A00: A00*B00,\n",
        " B10*A10: A10*B10}"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All we have are idempotency rules and commutations across the parties. If we had more then two outputs in a measurement, we would also see orthogonality rules. The only thing remaining before getting the relaxation is defining the objective function with the $I$ matrix, for which there is a helper function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "objective = define_objective_with_I(I, A, B)\n",
      "objective"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "A00 - A00*B00 - A00*B10 - A10*B00 + A10*B10 + B00"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we first initialize the SDP relaxation object. This step does not do any calculation, but it can take tons of parameters to fine-tune the resulting relaxation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "sdpRelaxation = SdpRelaxation(flatten([A, B]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are ready to generate the relaxation given the algebraic constraints. This is the step that is heavy in symbolic calculations. For complex problems or very high levels of relaxations, this can take a very long time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "sdpRelaxation.get_relaxation(level, objective=objective,\n",
      "                             substitutions=substitutions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Having obtained the relaxation, we can solve it with SDPA. Until now, all steps were symbolic. From here, everything is numeric."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(solve_sdp(sdpRelaxation))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-0.20710648902908663, -0.20710683598916801)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.2 Quantum bound on CGLMP at level 1+AB\n",
      "-------------------------------------------------\n",
      "We can quickly put this together from the above, while also preparing an extra set of monomials to be added to the moment matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "level = 1\n",
      "Alice, Bob = [3, 3], [3, 3]\n",
      "I = [[ 0, -1, -1,  0,  0],\n",
      "     [-1,  1,  1,  0,  1],\n",
      "     [-1,  1,  0,  1,  1],\n",
      "     [ 0,  0,  1,  0, -1],\n",
      "     [ 0,  1,  1, -1, -1]]\n",
      "A = generate_measurements(Alice, 'A')\n",
      "B = generate_measurements(Bob, 'B')\n",
      "AB = [Ai*Bj for Ai in flatten(A) for Bj in flatten(B)]\n",
      "substitutions = projective_measurement_constraints(A, B)\n",
      "objective = define_objective_with_I(I, A, B)\n",
      "sdpRelaxation = SdpRelaxation(flatten([A, B]))\n",
      "sdpRelaxation.get_relaxation(level, objective=objective, substitutions=substitutions,\n",
      "                             extramonomials=AB)\n",
      "print(solve_sdp(sdpRelaxation))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-0.3049512104453153, -0.30495152768528117)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "4. Moroder hierarchy and PPT conditions\n",
      "=======================\n",
      "Continuing with the CGLMP example, we can calculate the Moroder hierarchy and impose the PPT condition with changing only the SdpRelaxation object. Since the moment matrix has a tensor product structure, we need to supply two flat lists of operators instead of one, and ask for the Moroder structure with the PPT condition imposed. Everything else is identical, but we change the level to 2:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sdpRelaxation = SdpRelaxation([flatten(A), flatten(B)], \n",
      "                               hierarchy=\"moroder\", ppt=True)\n",
      "level = 2\n",
      "sdpRelaxation.get_relaxation(level, objective=objective, substitutions=substitutions)\n",
      "print(solve_sdp(sdpRelaxation))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-0.007949025231069329, -0.007949674643042704)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not surprisingly, the value is extremely close to zero."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "5. Full probabilities\n",
      "============\n",
      "5.1 Local randomness\n",
      "---------------------------\n",
      "This is a bit more involved than the previous scenarios, but it should not be surprising, as we need a lot more constraints, which correspond to the observed correlations. We will use [QuTiP](http://qutip.org/) to calculate the observed correlations, but they could easily be computed by NumPy if QuTiP fails to install -- NumPy is included in Anaconda. We define the joint probability function for a CHSH scenario as follows"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from math import sqrt, sin, cos, pi, atan\n",
      "from qutip import tensor, basis, sigmax, sigmay, expect, qeye\n",
      "def joint_probabilities():\n",
      "    psi = (tensor(basis(2,0),basis(2,0)) + \n",
      "           tensor(basis(2,1),basis(2,1))).unit()\n",
      "    A_0 = sigmax()\n",
      "    A_1 = sigmay()\n",
      "    B_0 = (-sigmay()+sigmax())/sqrt(2)\n",
      "    B_1 = (sigmay()+sigmax())/sqrt(2)\n",
      "    A_00 = (qeye(2) + A_0)/2\n",
      "    A_10 = (qeye(2) + A_1)/2\n",
      "    B_00 = (qeye(2) + B_0)/2\n",
      "    B_10 = (qeye(2) + B_1)/2\n",
      "\n",
      "    p=[expect(tensor(A_00, qeye(2)), psi),\n",
      "       expect(tensor(A_10, qeye(2)), psi),\n",
      "       expect(tensor(qeye(2), B_00), psi),\n",
      "       expect(tensor(qeye(2), B_10), psi),\n",
      "       expect(tensor(A_00, B_00), psi),\n",
      "       expect(tensor(A_00, B_10), psi),\n",
      "       expect(tensor(A_10, B_00), psi),\n",
      "       expect(tensor(A_10, B_10), psi)]\n",
      "    return p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Just as in the cases before, we need the operators for Alice and Bob. We need several of them, though, corresponding to the possible behaviour from which we can create the maximum guessing probability. Say, we are interested in the local guessing probability of Bob's second measurement, then we need two behaviours corresponding to the two projectors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Alice, Bob = [2, 2], [2, 2]\n",
      "P_0_A = generate_measurements(Alice, 'P_0_A')\n",
      "P_0_B = generate_measurements(Bob, 'P_0_B')\n",
      "P_1_A = generate_measurements(Alice, 'P_1_A')\n",
      "P_1_B = generate_measurements(Bob, 'P_1_B')\n",
      "substitutions0 = projective_measurement_constraints(P_0_A, P_0_B)\n",
      "substitutions1 = projective_measurement_constraints(P_1_A, P_1_B)\n",
      "substitutions = dict(substitutions0.items() + substitutions1.items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As in the Moroder hierarchy, we generate the relaxation from separate lists of variables, but now to have a block-diagonal structure. Note that the moment matrices should not be normalized."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "sdpRelaxation = SdpRelaxation([flatten([P_0_A, P_0_B]), flatten([P_1_A, P_1_B])],\n",
      "                              normalized=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we impose the constraints. The constraints are such that the relaxation should not generate localizing matrices. Such inequalities are called bounds in Ncpol2sdpa. Inequalities are always considered in >=0 format, so we only need to add the left-hand side."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probabilities = joint_probabilities()\n",
      "bounds = []\n",
      "k=0\n",
      "for i in range(len(Alice)):\n",
      "    bounds.append(P_0_A[i][0] + P_1_A[i][0] - probabilities[k])\n",
      "    k += 1\n",
      "for i in range(len(Bob)):\n",
      "    bounds.append(P_0_B[i][0] + P_1_B[i][0] - probabilities[k])\n",
      "    k += 1\n",
      "for i in range(len(Alice)):\n",
      "    for j in range(len(Bob)):\n",
      "        bounds.append(P_0_A[i][0]*P_0_B[j][0] + P_1_A[i][0]*P_1_B[j][0] -\n",
      "                          probabilities[k])\n",
      "        k += 1\n",
      "bounds.extend([-bound for bound in bounds])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The last line is necessary so the inequalities become equalities. We also need to normalize the top-left element of the moment matrices to add up to one. For this, there is a special string-based syntax, which allows us to reference elements of the moment matrices yet to be generated:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "bounds.extend([\"0[0,0]+1[0,0]-1\", \"-0[0,0]-1[0,0]+1\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The last element of defining the problem is the objective function. Since we must include the second projector of Bob's second measurement, but it is abscent in the Collins-Gisin notation, we could produce it as $\\mathbb{1}-B_{10}$. Since, however, the corresponding moment matrix is not normalized, we actually have to include the top-left element of that moment matrix instead of $\\mathbb{1}$. For this, we have a similar syntax that allows us to add variables of the moment matrix to the objective function. Remember also that we must have minimization, hence all signs are inverted."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "guessing_probability = - (P_0_B[1][0] - P_1_B[1][0])\n",
      "extraterm=\"-1[0,0]\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have everything to generate the SDP and solve the problem:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "level = 2\n",
      "sdpRelaxation.get_relaxation(level, objective=guessing_probability,\n",
      "                                 bounds=bounds,\n",
      "                                 substitutions=substitutions,\n",
      "                                 extraobjexpr=extraterm)\n",
      "print(solve_sdp(sdpRelaxation))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-0.5005460411610394, -0.5005460411630338)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "5.2 Global randomness\n",
      "----------------------------\n",
      "The procedure is largely the same as in the case of local randomness, but the number of behaviours will be much larger."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "P_00_A = generate_measurements(Alice, 'P_00_A')\n",
      "P_00_B = generate_measurements(Bob, 'P_00_B')\n",
      "P_01_A = generate_measurements(Alice, 'P_01_A')\n",
      "P_01_B = generate_measurements(Bob, 'P_01_B')\n",
      "P_10_A = generate_measurements(Alice, 'P_10_A')\n",
      "P_10_B = generate_measurements(Bob, 'P_10_B')\n",
      "P_11_A = generate_measurements(Alice, 'P_11_A')\n",
      "P_11_B = generate_measurements(Bob, 'P_11_B')\n",
      "substitutions0 = projective_measurement_constraints(P_00_A, P_00_B)\n",
      "substitutions1 = projective_measurement_constraints(P_01_A, P_01_B)\n",
      "substitutions2 = projective_measurement_constraints(P_10_A, P_10_B)\n",
      "substitutions3 = projective_measurement_constraints(P_11_A, P_11_B)\n",
      "substitutions = dict(substitutions0.items() + substitutions1.items() +\n",
      "                     substitutions2.items() + substitutions3.items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Say, we are interested in the $x=0$, $y=0$ setting, then the guessing probability will be"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "guessing_probability = - (P_00_A[0][0]*P_00_B[0][0] +\n",
      "                          P_01_A[0][0]*(1-P_01_B[0][0]) +\n",
      "                          (1-P_10_A[0][0])*P_10_B[0][0] +\n",
      "                          (1-P_11_A[0][0])*(1-P_11_B[0][0])) + 1\n",
      "extraterm=\"-3[0,0]\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bounds are defined identically:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bounds = []\n",
      "m = 0\n",
      "for i in range(len(Alice)):\n",
      "    for k in range(Alice[i]-1):\n",
      "        bounds.append(-P_00_A[i][k] - P_01_A[i][k] - P_10_A[i][k] - P_11_A[i][k] + probabilities[m])\n",
      "        m += 1\n",
      "for j in range(len(Bob)):\n",
      "    for l in range(Bob[j]-1):\n",
      "        bounds.append(-P_00_B[j][l] - P_01_B[j][l] -P_10_B[j][l] - P_11_B[j][l] + probabilities[m])\n",
      "        m += 1\n",
      "for i in range(len(Alice)):\n",
      "    for k in range(Alice[i]-1):\n",
      "        for j in range(len(Bob)):\n",
      "            for l in range(Bob[j]-1):\n",
      "                bounds.append(-P_00_A[i][k]*P_00_B[j][l]\n",
      "                              -P_01_A[i][k]*P_01_B[j][l]\n",
      "                              -P_10_A[i][k]*P_10_B[j][l]\n",
      "                              -P_11_A[i][k]*P_11_B[j][l]\n",
      "                              +probabilities[m])\n",
      "                m += 1\n",
      "bounds.extend([-bound for bound in bounds])\n",
      "bounds.extend([\"-0[0,0]-1[0,0]-2[0,0]-3[0,0]+1\", \"0[0,0]+1[0,0]+2[0,0]+3[0,0]-1\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The solution is given by"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sdpRelaxation = SdpRelaxation([flatten([P_00_A, P_00_B]),\n",
      "                               flatten([P_01_A, P_01_B]),\n",
      "                               flatten([P_10_A, P_10_B]),\n",
      "                               flatten([P_11_A, P_11_B])],\n",
      "                               normalized=False)\n",
      "sdpRelaxation.get_relaxation(level, objective=guessing_probability,\n",
      "                                 bounds=bounds,\n",
      "                                 substitutions=substitutions,\n",
      "                                 extraobjexpr=extraterm)\n",
      "print(solve_sdp(sdpRelaxation))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-0.42776038789446824, -0.427336765672365)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "6. Additional manipulation of the generated SDPs\n",
      "============================\n",
      "Until now, we never actually touched the generated SDPs, we just solved them by SDPA. We can, however, do arbitrary manipulations to them if we want to. In MATLAB, Yalmip provides a nice, high-level interface to work with conic optimization problems. The Python equivalent is [PICOS](http://picos.zib.de/). PICOS can be installed by typing ``pip install picos`` on the command line.\n",
      "\n",
      "Once we generate an SDP relaxation, we can convert it to a PICOS problem. Let us, for instance, revisit the Moroder hierarchy for CGLMP, but ask for a non-normalized version."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "level = 1\n",
      "Alice, Bob = [3, 3], [3, 3]\n",
      "I = [[ 0, -1, -1,  0,  0],\n",
      "     [-1,  1,  1,  0,  1],\n",
      "     [-1,  1,  0,  1,  1],\n",
      "     [ 0,  0,  1,  0, -1],\n",
      "     [ 0,  1,  1, -1, -1]]\n",
      "A = generate_measurements(Alice, 'A')\n",
      "B = generate_measurements(Bob, 'B')\n",
      "substitutions = projective_measurement_constraints(A, B)\n",
      "objective = define_objective_with_I(I, A, B)\n",
      "sdpRelaxation = SdpRelaxation([flatten(A), flatten(B)], \n",
      "                               hierarchy=\"moroder\", ppt=True, normalized=False)\n",
      "sdpRelaxation.get_relaxation(level, objective=objective, substitutions=substitutions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can convert this relaxation to a PICOS:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = convert_to_picos(sdpRelaxation)\n",
      "print P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---------------------\n",
        "optimization problem  (SDP):\n",
        "625 variables, 0 affine constraints, 325 vars in 1 SD cones\n",
        "\n",
        "X \t: (25, 25), continuous\n",
        "\n",
        "\tminimize X\n",
        "such that\n",
        "  X \u227d |0|\n",
        "---------------------\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then we can manually normalized the moment matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = P.get_variable('X')\n",
      "P.add_constraint(X[0, 0] == 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Just like Yalmip, PICOS can call a number of different solvers to deal with an SDP. By default, it looks for the most efficient one, and if it cannot find anything else, it will use [CVXOPT](http://cvxopt.org/). Here we explicitly force it use CVXOPT:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P.solve(solver='cvxopt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "*** Dualizing the problem...  ***\n",
        "--------------------------\n",
        "  cvxopt CONELP solver\n",
        "--------------------------\n",
        "     pcost       dcost       gap    pres   dres   k/t\n",
        " 0: -2.0428e-16 -7.1280e-17  4e+01  8e+00  5e+00  1e+00\n",
        " 1:  3.5214e-01  2.8082e-01  3e+00  9e-01  5e-01  3e-02\n",
        " 2:  2.4459e-01  2.3950e-01  5e-01  2e-01  1e-01  2e-02\n",
        " 3:  1.4801e-01  1.4670e-01  5e-01  2e-01  9e-02  2e-02\n",
        " 4:  9.0776e-02  9.0613e-02  1e-01  4e-02  2e-02  4e-03\n",
        " 5:  6.8427e-02  6.8538e-02  5e-02  1e-02  9e-03  2e-03\n",
        " 6:  5.8733e-02  5.8759e-02  1e-02  3e-03  2e-03  4e-04\n",
        " 7:  5.5624e-02  5.5630e-02  2e-03  5e-04  3e-04  7e-05\n",
        " 8:  5.5035e-02  5.5036e-02  1e-04  4e-05  3e-05  6e-06\n",
        " 9:  5.4988e-02  5.4988e-02  2e-05  5e-06  3e-06  7e-07\n",
        "10:  5.4981e-02  5.4981e-02  6e-07  2e-07  1e-07  2e-08\n",
        "11:  5.4981e-02  5.4981e-02  7e-08  2e-08  1e-08  3e-09\n",
        "12:  5.4981e-02  5.4981e-02  7e-09  2e-09  1e-09  3e-10\n",
        "Optimal solution found.\n",
        "cvxopt status: optimal\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "{'cvxopt_sol': {'dual infeasibility': 1.2275757587442167e-09,\n",
        "  'dual objective': 0.0549811036763852,\n",
        "  'dual slack': 2.5804558773916926e-11,\n",
        "  'gap': 6.591149608762571e-09,\n",
        "  'iterations': 12,\n",
        "  'primal infeasibility': 2.0265452872062782e-09,\n",
        "  'primal objective': 0.05498110365333006,\n",
        "  'primal slack': 2.619608016089217e-11,\n",
        "  'relative gap': 1.198802710028813e-07,\n",
        "  'residual as dual infeasibility certificate': None,\n",
        "  'residual as primal infeasibility certificate': None,\n",
        "  's': <625x1 matrix, tc='d'>,\n",
        "  'status': 'optimal',\n",
        "  'x': <326x1 matrix, tc='d'>,\n",
        "  'y': <81x1 matrix, tc='d'>,\n",
        "  'z': <625x1 matrix, tc='d'>},\n",
        " 'obj': 0.05498110366485763,\n",
        " 'status': 'optimal',\n",
        " 'time': 0.19536709785461426}"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "PICOS cannot use SDPA to solve a problem, but it can export to SDPA format."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "7. Alternative SDP solvers\n",
      "===============\n",
      "7.1 Other members of the SDPA family\n",
      "------------------------------------------------\n",
      "The regular (double) precision solver of SDPA is the most difficult to compile. The source files are also available at the same place for the quad-double precision solver SDPA_QD, and the arbitrary-precision solver SDPA_GMP, which are infinitely easier to compile, requiring just one external library each.\n",
      "\n",
      "The SDPA solvers come with a param.sdpa file for default parameter settings. This file is very similar for SDPA_QD and SDPA_GMP, but it is different for the double-precision solver. The parameter file should not be mixed up, as it leads to undefined behaviour. For SDPA_QD and SDPA_GMP, I recommend the following pattern of use:\n",
      "\n",
      "1. Use the ``write_to_sdpa`` function of Ncpol2sdpa to write the SDP relaxation to a file that any SDP solver can use. The target directory should be where the param.sdpa file of SDPA_QD and SDPA_GMP resides. The filename should have the extension ``.dat-s``.\n",
      "2. Run either SDPA_QD or SDPA_GMP in that directory.\n",
      "3. Process the result in Ncpol2sdpa with ``read_sdpa_out`` if you want to analyze the solution matrix, find a rank loop (``find_rank_loop``), or do an SOS decomposition (``sos_decomposition``).\n",
      "\n",
      "It is a bit tedious, but since the high-precision solvers are approximately 1,000x slower, this procedure ensures a fool-proof workflow.\n",
      "\n",
      "7.2 Mosek and CVXOPT\n",
      "---------------------------\n",
      "For CVXOPT, the only option is via PICOS. It is, however, extremely slow. [Mosek](http://mosek.com/) is a better alternative, but it requires a university email address to get a free licence, and it seems to consume more memory than SDPA. To use Mosek, you can either use Picos and specify ``mosek7`` as the solver, or you can directly convert it to Mosek format from Ncpol2sdpa with the function ``convert_to_mosek``.\n",
      "\n",
      "7.3 Execution on a cluster\n",
      "-----------------------------------\n",
      "SDPA is extremely well-suited to run on a cluster, or at least on a high-performance computing node. The procedure of submitting an SDP to a cluster can be greatly simplified. Follow step 1 in Section 7.1 to get a problem in SDPA format. Assume that you have a job script called ``job_sdp.sh`` on the cluster in your home directory that takes two parameters, the name of the SDPA file and the output file, and sends you an email when the calculation is ready. Then, if the hostname of the cluster is ``cluster``, you can use this script to upload the problem and schedule the execution:\n",
      "\n",
      "```\n",
      "#!/bin/bash\n",
      "scp $1 cluster:\n",
      "ssh username@cluster qsub job_sdp.sh $1 ${1%.*}.out\n",
      "```\n",
      "where the parameter is the name of the SDPA file (e.g., ``problem.dat-s``). You might have to change the command ``qsub`` to the job submission command used on the cluster."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "References\n",
      "======\n",
      "[1] Pironio, S.; Navascu\u00e9s, M. & Ac\u00edn, A. [Convergent relaxations of polynomial optimization problems with noncommuting variables](http://arxiv.org/abs/0903.4368). _SIAM Journal on Optimization_, 2010, 20, pp. 2157-2180.\n",
      "\n",
      "[2] Wittek, P. [Ncpol2sdpa -- Sparse Semidefinite Programming Relaxations for Polynomial Optimization Problems of Noncommuting Variables](http://arxiv.org/abs/1308.6029). _To appear in the ACM Transactions on Mathematical Software_, 2015."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
